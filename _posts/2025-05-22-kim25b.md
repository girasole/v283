---
title: Approximate Thompson Sampling for Learning Linear Quadratic Regulators with
  $O(\sqrtT)$ Regret
abstract: We propose a novel Thompson sampling algorithm that learns linear quadratic
  regulators (LQR) with a Bayesian regret bound of $O(\sqrt{T})$. Our method leverages
  Langevin dynamics with a carefully designed preconditioner and incorporates a simple
  excitation mechanism. We show that the excitation signal drives the minimum eigenvalue
  of the preconditioner to grow over time, thereby accelerating the approximate posterior
  sampling process. Furthermore, we establish nontrivial concentration properties
  of the approximate posteriors generated by our algorithm. These properties enable
  us to bound the moments of the system state and attain an $O(\sqrt{T})$ regret bound
  without relying on the restrictive assumptions that are often used in the literature.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kim25b
month: 0
tex_title: Approximate Thompson Sampling for Learning Linear Quadratic Regulators
  with $O(\sqrt{T})$ Regret
firstpage: 378
lastpage: 391
page: 378-391
order: 378
cycles: false
bibtex_author: Kim, Yeoneung and Kim, Gihun and Park, Jiwhan and Yang, Insoon
author:
- given: Yeoneung
  family: Kim
- given: Gihun
  family: Kim
- given: Jiwhan
  family: Park
- given: Insoon
  family: Yang
date: 2025-05-22
address:
container-title: Proceedings of the 7th Annual Learning for Dynamics \& Control Conference
volume: '283'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 5
  - 22
pdf: https://raw.githubusercontent.com/mlresearch/v283/main/assets/kim25b/kim25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
