---
title: Efficient Duple Perturbation Robustness in Low-rank MDPs
abstract: The pursuit of robustness has recently been a popular topic in reinforcement
  learning (RL) research, yet the existing methods generally suffer from computation
  issues that obstruct their real-world implementation. In this paper, we consider
  MDPs with low-rank structures, where the transition kernel can be written as a linear
  product of feature map and factors. We introduce *duple perturbation* robustness,
  i.e. perturbation on both the feature map and the factors, via a novel characterization
  of $(\xi,\eta)$-ambiguity sets featuring computational efficiency. Our novel low-rank
  robust MDP formulation is compatible with the low-rank function representation view,
  and therefore, is naturally applicable to practical RL problems with large or even
  continuous state-action spaces. Meanwhile, it also gives rise to a provably efficient
  and practical algorithm with theoretical convergence rate guarantee. Lastly, the
  robustness of our proposed approach is justified by numerical experiments, including
  classical control tasks with continuous state-action spaces.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hu25b
month: 0
tex_title: Efficient Duple Perturbation Robustness in Low-rank MDPs
firstpage: 723
lastpage: 737
page: 723-737
order: 723
cycles: false
bibtex_author: Hu, Yang and Ma, Haitong and Li, Na and Dai, Bo
author:
- given: Yang
  family: Hu
- given: Haitong
  family: Ma
- given: Na
  family: Li
- given: Bo
  family: Dai
date: 2025-05-22
address:
container-title: Proceedings of the 7th Annual Learning for Dynamics \& Control Conference
volume: '283'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 5
  - 22
pdf: https://raw.githubusercontent.com/mlresearch/v283/main/assets/hu25b/hu25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
