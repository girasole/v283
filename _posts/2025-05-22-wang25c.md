---
title: Multi-Constraint Safe Reinforcement Learning via Closed-form Solution for Log-Sum-Exp
  Approximation of Control Barrier Functions
abstract: The safety of training task policies and their subsequent application using
  reinforcement learning (RL) methods has become a focal point in the field of safe
  RL. A central challenge in this area remains the establishment of theoretical guarantees
  for safety during both the learning and deployment processes. Given the successful
  implementation of Control Barrier Function (CBF)-based safety strategies in a range
  of control-affine robotic systems, CBF-based safe RL demonstrates significant promise
  for practical applications in real-world scenarios. However, integrating these two
  approaches presents several challenges. First, embedding safety optimization within
  the RL training pipeline requires that the optimization outputs be differentiable
  with respect to the input parameters, a condition often referred to as differentiable
  optimization, which is non-trivial to solve. Second, the differentiable optimization
  framework confronts significant efficiency issues, especially when dealing with
  multi-constraint problems. To address these challenges, this paper presents a CBF-based
  safe RL architecture that effectively mitigates the issues outlined above. The proposed
  approach constructs a continuous AND logic approximation for the multiple constraints
  using a single composite CBF. By leveraging this approximation, a close-form solution
  of the quadratic programming is derived for the policy network in RL, thereby circumventing
  the need for differentiable optimization within the end-to-end safe RL pipeline.
  This strategy significantly reduces computational complexity because of the closed-form
  solution while maintaining safety guarantees. Simulation results demonstrate that,
  in comparison to existing approaches relying on differentiable optimization, the
  proposed method significantly reduces training computational costs while ensuring
  provable safety throughout the training process. This advancement opens up promising
  potential for applications in large-scale optimization problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang25c
month: 0
tex_title: Multi-Constraint Safe Reinforcement Learning via Closed-form Solution for
  Log-Sum-Exp Approximation of Control Barrier Functions
firstpage: 698
lastpage: 710
page: 698-710
order: 698
cycles: false
bibtex_author: Wang, Chenggang and Wang, Xinyi and Dong, Yutong and Song, Lei and
  Guan, Xinping
author:
- given: Chenggang
  family: Wang
- given: Xinyi
  family: Wang
- given: Yutong
  family: Dong
- given: Lei
  family: Song
- given: Xinping
  family: Guan
date: 2025-05-22
address:
container-title: Proceedings of the 7th Annual Learning for Dynamics \& Control Conference
volume: '283'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 5
  - 22
pdf: https://raw.githubusercontent.com/mlresearch/v283/main/assets/wang25c/wang25c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
